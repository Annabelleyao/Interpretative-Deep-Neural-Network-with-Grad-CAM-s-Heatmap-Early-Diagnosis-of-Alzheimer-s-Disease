# -*- coding: utf-8 -*-
"""ViT_apply.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gt1TlAgQl9g8-QTPHCXnqfISrPFdTOGA
"""

# !pip install transformers
import torch
import torch.nn as nn
import numpy as np
from transformers import ViTModel
from transformers import ViTModel, ViTConfig
from torch.optim import Adam
from tqdm import tqdm
import os
from skimage.transform import resize
from skimage.io import imread

# from google.colab import drive
# drive.mount('/content/drive')

import platform
import sys

def linux_distribution():
  try:
    return platform.linux_distribution()
  except:
    return "N/A"

def dist():
  try:
    return platform.dist()
  except:
    return "N/A"

print("""Python version: %s
dist: %s
linux_distribution: %s
system: %s
machine: %s
platform: %s
uname: %s
version: %s
mac_ver: %s
""" % (
sys.version.split('\n'),
str(dist()),
linux_distribution(),
platform.system(),
platform.machine(),
platform.platform(),
platform.uname(),
platform.version(),
platform.mac_ver(),
))

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# TRAIN_INDICES_FILE = 'train_indices.txt'
# TEST_INDICES_FILE = 'test_indices.txt'

# !unzip /content/drive/MyDrive/MRIdataset.zip

# from datasets import load_dataset
# Load dataset
import os
# DIR = './MRIdataset'
# os.path.exists(DIR)
# os.listdir(DIR)
datadir='./MRIdataset'

class MRIDataset(Dataset):
    def __init__(self, images, labels, transform=None):
        self.images = images
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        image = self.images[idx]
        label = self.labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

import torch
# your loading code
# Categories=['Mild_Demented','Moderate_Demented','Very_Mild_Demented','Non_Demented']
def inputimg(cat):
    Categories=[cat]
    flat_data_arr=[] #input array
    target_arr=[] #output array
    # !pip install -q datasets

    from datasets import load_dataset
    import os

    # Load dataset

    for i in Categories:
        print(f'loading... category : {i}')
        path=os.path.join(i)
        cnt = 0
        for img in os.listdir(path):
            img_array=imread(os.path.join(path,img))
            # print(img_array.shape)
            img_resized=resize(img_array,(224,224,3))
            img_resized = np.transpose(img_resized, (2, 0, 1))
            flat_data_arr.append(img_resized)
            target_arr.append(Categories.index(i))
            cnt = cnt + 1
            # if cnt > 50: break
        print(f'loaded category:{i} successfully')

    # convert your data to tensors
    flat_data_arr = [torch.from_numpy(img).float() for img in flat_data_arr]
    target_arr = torch.tensor(target_arr, dtype=torch.long)
    torch.cuda.is_available()

    import os

    img_num = 1;

    train_indices = np.arange(0)
    test_indices = np.arange(0,img_num)

    print("training data size: ", len(train_indices))
    print("testing data size: ", len(test_indices))
    print(len(flat_data_arr))

    ### double check no overlap between train and test
    for i in train_indices:
        if i in test_indices:
            print("overlap")
    train_data = [flat_data_arr[int(i)] for i in train_indices]
    test_data = [flat_data_arr[int(i)] for i in test_indices]
    train_target = [target_arr[int(i)] for i in train_indices]
    test_target = [target_arr[int(i)] for i in test_indices]

    train_dataset = MRIDataset(train_data, train_target)
    test_dataset = MRIDataset(test_data, test_target)
# train_dataset = MRIDataset(flat_data_arr[train_indices], target_arr[train_indices])
# test_dataset = MRIDataset(flat_data_arr[test_indices], target_arr[test_indices])

    class ViT(nn.Module):

      def __init__(self, config=ViTConfig(), num_labels=20,
                   model_checkpoint='google/vit-base-patch16-224-in21k'):

            super(ViT, self).__init__()

            self.vit = ViTModel.from_pretrained(model_checkpoint, add_pooling_layer=False)
            self.classifier = (
                nn.Linear(config.hidden_size, num_labels)
            )

      def forward(self, x):
       x = self.vit(x)['last_hidden_state']
       # Use the embedding of [CLS] token
       output = self.classifier(x[:, 0, :])
       return output

    # from google.colab import drive
    # drive.mount('/content/drive')

    use_cuda = torch.cuda.is_available()
    device = torch.device("cuda" if use_cuda else "cpu")
    model = ViT().to(device) # we do not specify ``weights``, i.e. create untrained model
    model.load_state_dict(torch.load('./model.pth',map_location=torch.device('cpu')))

# !pip install grad-cam

    from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad
    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
    from pytorch_grad_cam.utils.image import show_cam_on_image
    from torchvision.models import resnet50

    K = 0

    image = test_dataset[K][0]

    input_tensor = image.unsqueeze(0).to(torch.device('cpu'))

    target_layers = [model.vit.encoder.layer[-2].layernorm_before]

    def reshape_transform(tensor, height=14, width=14):
        result = tensor[:, 1 :  , :].reshape(tensor.size(0),
            height, width, tensor.size(2))
        print(np.shape(tensor))
        print(np.shape(result))

        # Bring the channels to the first dimension,
        # like in CNNs.
        result = result.transpose(2, 3).transpose(1, 2)
        return result

    cam = GradCAM(model=model, target_layers=target_layers, reshape_transform=reshape_transform)
    # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.
    # grayscale_cam = cam(input_tensor=input_tensor, targets=targets)
    grayscale_cam = cam(input_tensor=input_tensor)
    rgb_img = test_dataset[K][0].permute(1, 2, 0).numpy()

    # # # In this example grayscale_cam has only one image in the batch:
    grayscale_cam = grayscale_cam[0, :]
    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
    from PIL import Image
    # Image.fromarray(visualization)
    im1 = Image.fromarray(visualization)
    import matplotlib.pyplot as plt
    from datetime import datetime
# Getting the current date and time
    dt = datetime.now()

    # getting the timestamp
    ts = datetime.timestamp(dt)
    address='./static/output/{}.jpg'.format(ts)
    im1=im1.save(address)
    # plt.imshow(visualization)
    # plt.show()
    image = np.expand_dims(image,axis=0)
    image = torch.tensor(image)

    output = model(image.to(device))

    # print(output.argmax(dim=1).cpu().numpy())

    result=''
    if(output.argmax(dim=1).cpu().numpy()==0):
        result = "Mild Demented"

    if(output.argmax(dim=1).cpu().numpy()==1):
        result ="Moderate Demented"

    if(output.argmax(dim=1).cpu().numpy()==2):
        result ="Very Mild Demented"

    if(output.argmax(dim=1).cpu().numpy()==3):
        result ="Non Demented"
    
    return result, address

#  Mild_Demented -0
#  Moderate_Demented -1
#  Very_Mild_Demented-2
#  Non_Demented-3

from flask import Flask, request, render_template
from PIL import Image
import numpy as np
from datetime import datetime
app = Flask(__name__)

@app.route('/')
def upload_file():
    return render_template('upload.html')

@app.route('/uploader', methods=['GET', 'POST'])
def upload_image():
    if request.method == 'POST':
        f = request.files['file']
        # 转换为灰度图像
        # 处理或保存二维数组
    # Getting the current date and time
        dt = datetime.now()
    # getting the timestamp
        address='./tests/{}hi'.format(dt)
        os.makedirs(address, exist_ok=True)
        image = Image.open(f.stream)
        image.save('{}/{}'.format(address, '1.jpg'))
        outputaddress,outputresult= inputimg(address)
        return '{}:{}'.format(outputaddress,outputresult)
    

if __name__ == '__main__':    
   app.run(host='0.0.0.0', port=80)



